---
title: <뉴스 번역> 중국에서 무료로 공개된 AI 모델 DeepSeek이 과학자들을 전율케 했다
date: 2025-01-18
categories: [영어 공부, 뉴스 번역]
tags: [News, Nature]
description: DeepSeek-R1 모델은 추론 문제에서 OpenAI의 o1 모델과 비슷한 성능을 보였으며, 연구자들이 이를 검증하는 경우 무료로 사용할 수 있다.
published: true
---

***

* 학습 목적의 번역이며, 오역이나 의역이 포함될 수 있습니다.

***

* Journal: Nature
* Date: 2025년 01월 23일
* Author: Elizabeth Gibney
* Link: <https://www.nature.com/articles/d41586-025-00229-6>

***
<figure align="center">
  <img src="https://media.nature.com/lw767/magazine-assets/d41586-025-00229-6/d41586-025-00229-6_50504086.jpg?as=webp" width="600px" height="450px" alt="">
  <figcaption style="font-size:12px">중국의 DeepSeek 사는 작년 거대 언어 모델의 첫 버전을 공개했다.</figcaption>
  <figcaption style="font-size:12px">Credit: Koshiro K/Alamy</figcaption>
</figure>

<br>

<p>
&ensp;중국에서 개발된 거대 언어 모델 DeepSeek-R1이 합리적인 가격과 모델 구조를 공개했다는 장점을 바탕으로 OpenAI의 o1 같은 추론 모델에 대한 경쟁자로 등장해 과학자들을 전율케 하고 있습니다.<br><br>
&ensp;이 모델은 사람의 추론 과정과 비슷하게 단계적으로 응답을 생성합니다. 이는 기존의 언어 모델보다 과학적 문제를 더 잘 풀 수 있도록 했으며, 이를 바탕으로 연구 분야에 활용할 수 있게 되었습니다. R1 모델의 최초 테스트는 1월 20일에 공개되었으며, 화학, 수학, 그리고 코딩 관련 과제에 대해 OpenAI가 9월 공개해 연구자들을 놀라게 했던 o1 모델과 유사한 성능을 보였습니다.<br><br>
&ensp;AI 연구자이자 영국에 위치한 AI 컨설팅 회사 DAIR.AI의 공동 투자자인 Elvis Saravia는 X에 "이는 매우 놀랍고 전혀 예상치 못한 일입니다."라고 적기도 했습니다.<br><br>
&ensp;R1 모델이 놀라운 이유는 또 있습니다. 항저우에 위치한 AI 모델 개발 관련 스타트업인 DeepSeek은 R1 모델의 구조를 무료로 공개했으며, 이는 연구자들이 해당 모델에 사용된 알고리즘을 연구하고 개발할 수 있다는 의미입니다. MIT 라이선스 하에 공개되었으며, 이 모델을 자유롭게 재사용할 수 있습니다. 다만, 학습용 데이터의 경우 공개되지 않았기 때문에, 완전한 오픈소스는 아닙니다.<br><br>
&ensp;독일 에를랑겐에 위치한 막스 플랑크 광 과학 연구소에서 Artificial Scientist Lab을 이끄는 Mario Krenn은 "DeepSeek의 개방성은 꽤 주목할 만합니다."라고 언급했습니다. 그는 o1이나 최신 버전 o3를 비롯해 캘리포니아 샌프란시스코의 OpenAI가 개발한 모델들은 내부 구조가 아예 공개되어 있지 않다고 언급하며, 두 회사를 비교했습니다.<br><br>
&ensp;DeppSeek이 R1을 학습시키는 데 사용한 비용을 공개하지는 않았지만, 이 모델 기반 인터페이스를 사용할 때 청구되는 비용이 o1 모델을 사용하는 비용의 30분의 1에 불과합니다. 회사는 R1 모델의 소형 버전도 만들어 연구자들이 한정된 컴퓨팅 자원으로 모델을 사용할 수 있도록 했습니다. Krenn은 "o1 모델을 사용하는데 300유로 이상이 필요하지만, R1 모델을 사용하는 경우 10달러 이하로 사용할 수 있습니다. 이 큰 차이는 선택하는 과정에서 많은 영향을 줄 것입니다."라고 밝혔습니다.<br> 
</p>

<h3>기존 모델에 대한 도전</h3>

<p>
&ensp;R1 모델은 중국에서 벌어지는 거대 언어 모델 개발 유행의 일환입니다. 헤지펀드에서 분사한 DeepSeek은 지난달 V3라 불리는 챗봇을 공개하기 전까지는 적은 예산으로 인해 라이벌들보다 알려지지 않은 회사였습니다.<br><br>
&ensp;전문가들은 R1 모델을 학습시키는 데 6백만 달러의 하드웨어 대여 비용이 발생했다고 추정하고 있는데, 이는 메타의 Llama 3.1405B 모델이 사용한 6천만 달러가량의 컴퓨팅 자원의 11분의 1에 불과합니다.<br><br>
&ensp;미국이 중국 회사들을 상대로 AI 개발을 위한 고성능 컴퓨터 칩을 사용하지 못하도록 수출을 통제한 상황에서 R1 모델을 성공적으로 개발한 것은 DeepSeek의 놀라운 점 중 하나입니다. 워싱턴 시애틀에서 AI를 연구하는 François Chollet은 "이 모델이 중국에서 나왔다는 사실은 계산 스케일만 고려하는 것이 아니라, 컴퓨팅 자원의 효율적인 사용도 고려해야 함을 의미합니다."라고 주장했습니다.<br><br>
&ensp;워싱턴 Bellevue사의 기술 전문가이자, 대만의 몰입형 기술 회사인 HTC에서 일하는 Alvin Wang Graylin은 X에 "DeepSeek의 발전은 미국이 가졌었던 기술적 우위가 상당히 좁혀졌음을 보여줍니다. 양국은 승자 없는 군비 경쟁을 지속하기보다, 첨단 AI를 개발하기 위해 서로 협력해야 합니다."라고 적었습니다.<br>
</p>

<h3>생각의 연계</h3>

<p>
&ensp;LLM 모델을 위해서는 수십억개 이상의 글이 필요하고, 이를 토큰이라 불리는 작은 단위로 잘라 데이터에 있는 패턴을 학습시켜야 합니다. 이 패턴은 모델이 다음에 올 토큰을 예측할 수 있도록 합니다. 하지만, LLM은 환각이라 불리는 사실을 날조하는 현상을 보이기도 하며, 추론에 한계점을 보이기도 합니다.<br><br>
&ensp;o1모델과 마찬가지로, R1은 '생각의 연계'라는 방법을 사용해 복잡한 문제를 해결하는 과정에서, 이전의 내용을 다시 떠올리기도 하고 접근 방식을 평가하기도 합니다. DeepSeek은 R1 모델을 만들 때 V3 모델에 대한 강화 학습을 하며 미세 조정을 진행했는데, 이 과정에서 모델이 정답에 도달하고 생각을 설명하는 방식으로 문제를 해결할 때마다 보상을 주었습니다.<br>  
</p>

<figure align="center">
  <img src="https://media.nature.com/lw767/magazine-assets/d41586-025-00229-6/d41586-025-00229-6_50504214.jpg?as=webp" width="600px" height="450px" alt="">
  <figcaption style="font-size:12px">DeepSeek은 3가지 버전의 LLM을 수학, 코딩, 추론 문제 영역에서 OpenAI의 모델과 비교했고, DeepSeek-R1 모델이 수학과 코딩 영역에서 o1 모델과 비슷하거나 앞선다는 것을 보여주었다.</figcaption>
</figure>

<p>
&ensp;에든버러 대학의 AI 연구자 Wenda Li는 제한된 컴퓨팅 자원을 사용하게 되면 혁신적인 알고리즘을 사용해야 할 때가 있다고 언급했습니다. 강화 학습을 진행하는 동안 연구진은 분리된 네트워크에서 모델을 평가하지 않고, 진행 단계마다 평가를 진행했습니다. 케임브리지 대학의 컴퓨터공학자 Mateja Jamnik은 이를 통해 학습과 실행 비용을 줄일 수 있다고 설명했습니다. 연구진은 이에 더해 각 문제에 관련된 일부만 활성화하는 '혼합된 전문가'라는 방법을 사용하기도 했습니다.<br><br>
&ensp;모델 연구 논문에 보고된 벤치마크 검증에 따르면, DeepSeek-R1 모델은 버클리의 캘리포니아 대학의 연구진이 만든 수학 문제 데이터셋인 MATH-500에 대해 97.3%의 정확도를 보였으며, Codeforces에서 96.3%의 사람보다 나은 결과를 보여주었습니다. o3 모델과 비교하지는 않았지만, 이는 o1 모델과 비슷한 성능입니다.<br><br>
&ensp;물론 벤치마크 검증으로 모델의 추론과 일반화를 정확히 평가할 수 없고, 단순히 검증을 통과만 한 것일 수 있습니다. 하지만 케임브리지 대학의 컴퓨터공학자 Marco Dos Santos는 R1이 공개되면서 '생각의 연계'라는 방식이 연구자들에게 공개되었으며 이는 모델의 추론 과정을 더 잘 해석할 수 있게 한다고 주장했습니다.<br><br>
&ensp;이미 과학자들이 R1의 능력을 시험하고 있습니다. Krenn은 두 라이벌 모델에 3,000개의 연구 아이디어에 대해 얼마나 흥미로운지 순위를 매기도록 했고, 이를 인간이 만든 순위와 비교했습니다. R1 모델이 o1 모델보다 성능이 약간 낮긴 했지만, 양자 광학 같은 일부 영역에 대해서는 o1 모델을 제치기도 했으며, Krenn은 이를 "매우 인상적입니다."라고 평가했습니다.
</p>